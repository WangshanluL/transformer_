# Transformer å®ç°

è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨ PyTorch å®ç°çš„ Transformer æ¨¡å‹ï¼Œç”¨äºæœºå™¨ç¿»è¯‘ä»»åŠ¡ã€‚ä»£ç ç»“æ„æ¸…æ™°ï¼Œæ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºç†è§£å’Œæ‰©å±•ã€‚

## é¡¹ç›®ç»“æ„

```
transformer_project/
â”œâ”€â”€ models/                  # æ¨¡å‹æ¶æ„
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ transformer.py      # Transformerä¸»æ¨¡å‹
â”‚   â”œâ”€â”€ encoder.py          # ç¼–ç å™¨
â”‚   â””â”€â”€ decoder.py          # è§£ç å™¨
â”‚
â”œâ”€â”€ modules/                 # åŸºç¡€ç»„ä»¶
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ attention.py        # æ³¨æ„åŠ›æœºåˆ¶
â”‚   â”œâ”€â”€ feedforward.py      # å‰é¦ˆç½‘ç»œ
â”‚   â”œâ”€â”€ embedding.py        # ä½ç½®ç¼–ç 
â”‚   â””â”€â”€ mask.py             # æ©ç ç”Ÿæˆ
â”‚
â”œâ”€â”€ utils/                   # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ data_utils.py       # æ•°æ®å¤„ç†å·¥å…·
â”‚
â”œâ”€â”€ config/                  # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py           # æ¨¡å‹é…ç½®
â”‚
â”œâ”€â”€ scripts/                 # è„šæœ¬æ–‡ä»¶
â”‚   â”œâ”€â”€ train.py            # è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ test.py             # æµ‹è¯•è„šæœ¬
â”‚
â”œâ”€â”€ requirements.txt         # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md               # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

## æ¨¡å—è¯´æ˜

### ğŸ“¦ models/ - æ¨¡å‹æ¶æ„å±‚
åŒ…å«å®Œæ•´çš„æ¨¡å‹å®šä¹‰
- `transformer.py`: å®Œæ•´çš„ Transformer æ¨¡å‹
- `encoder.py`: ç¼–ç å™¨åŠç¼–ç å™¨å±‚
- `decoder.py`: è§£ç å™¨åŠè§£ç å™¨å±‚

### ğŸ”§ modules/ - åŸºç¡€ç»„ä»¶å±‚
å¯å¤ç”¨çš„ç¥ç»ç½‘ç»œç»„ä»¶
- `attention.py`: ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›å’Œå¤šå¤´æ³¨æ„åŠ›
- `feedforward.py`: é€ä½ç½®å‰é¦ˆç¥ç»ç½‘ç»œ
- `embedding.py`: æ­£å¼¦ä½ç½®ç¼–ç 
- `mask.py`: å„ç§æ©ç ç”Ÿæˆå‡½æ•°

### ğŸ› ï¸ utils/ - å·¥å…·å±‚
æ•°æ®å¤„ç†å’Œè¾…åŠ©å‡½æ•°
- `data_utils.py`: ç¿»è¯‘è¯­æ–™åº“å¤„ç†ç±»

### âš™ï¸ config/ - é…ç½®å±‚
é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®å‚æ•°
- `config.py`: æ¨¡å‹è¶…å‚æ•°é…ç½®

### ğŸš€ scripts/ - è„šæœ¬å±‚
å¯æ‰§è¡Œçš„è®­ç»ƒå’Œæµ‹è¯•è„šæœ¬
- `train.py`: è®­ç»ƒæ¨¡å‹
- `test.py`: æµ‹è¯•æ¨¡å‹

## ä½¿ç”¨æ–¹æ³•

### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### è®­ç»ƒæ¨¡å‹

```bash
python scripts/train.py
```

### æµ‹è¯•æ¨¡å‹

```bash
python scripts/test.py
```

### è‡ªå®šä¹‰è®­ç»ƒ

```python
from utils.data_utils import TranslationCorpus
from models.transformer import Transformer
from config.config import TransformerConfig

# å‡†å¤‡æ•°æ®
sentences = [
    ['æºè¯­è¨€å¥å­1', 'ç›®æ ‡è¯­è¨€å¥å­1'],
    ['æºè¯­è¨€å¥å­2', 'ç›®æ ‡è¯­è¨€å¥å­2'],
    # ...
]

# åˆ›å»ºè¯­æ–™åº“
corpus = TranslationCorpus(sentences)

# æ›´æ–°é…ç½®
config = TransformerConfig()
config.update_from_corpus(corpus)

# åˆ›å»ºæ¨¡å‹
model = Transformer(
    src_vocab_size=config.src_vocab_size,
    tgt_vocab_size=config.tgt_vocab_size,
    src_len=config.src_len,
    tgt_len=config.tgt_len,
    d_embedding=config.d_embedding,
    n_layers=config.n_layers,
    n_heads=config.n_heads,
    d_k=config.d_k,
    d_v=config.d_v,
    d_ff=config.d_ff
)

# è®­ç»ƒæ¨¡å‹
# ...
```

## æ¨¡å‹å‚æ•°

é»˜è®¤é…ç½®ï¼š
- åµŒå…¥ç»´åº¦ (d_embedding): 512
- ç¼–ç å™¨/è§£ç å™¨å±‚æ•° (n_layers): 6
- å¤šå¤´æ³¨æ„åŠ›å¤´æ•° (n_heads): 8
- Q, K ç»´åº¦ (d_k): 64
- V ç»´åº¦ (d_v): 64
- å‰é¦ˆç½‘ç»œéšè—å±‚ç»´åº¦ (d_ff): 2048
- æ‰¹æ¬¡å¤§å° (batch_size): 3
- è®­ç»ƒè½®æ•° (epochs): 5
- å­¦ä¹ ç‡ (learning_rate): 0.0001

## é¡¹ç›®ç‰¹ç‚¹

âœ… **æ¸…æ™°çš„åˆ†å±‚ç»“æ„**ï¼šæŒ‰åŠŸèƒ½åˆ†ä¸º modelsã€modulesã€utilsã€configã€scripts
âœ… **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¯ä¸ªæ¨¡å—èŒè´£å•ä¸€ï¼Œæ˜“äºç»´æŠ¤
âœ… **æ˜“äºæ‰©å±•**ï¼šå¯ä»¥è½»æ¾æ·»åŠ æ–°çš„ç»„ä»¶æˆ–æ¨¡å‹
âœ… **é…ç½®é›†ä¸­ç®¡ç†**ï¼šæ‰€æœ‰è¶…å‚æ•°åœ¨ config ä¸­ç»Ÿä¸€è®¾ç½®
âœ… **å®Œå–„çš„æ–‡æ¡£**ï¼šæ¯ä¸ªæ¨¡å—éƒ½æœ‰è¯¦ç»†æ³¨é‡Š

## æ³¨æ„äº‹é¡¹

1. æœ¬å®ç°æ˜¯ä¸€ä¸ªæ•™å­¦ç¤ºä¾‹ï¼Œæ•°æ®é›†è¾ƒå°
2. å®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤§çš„æ•°æ®é›†å’Œæ›´é•¿çš„è®­ç»ƒæ—¶é—´
3. å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´æ¨¡å‹å‚æ•°å’Œè®­ç»ƒå‚æ•°
4. å»ºè®®ä½¿ç”¨ GPU è¿›è¡Œè®­ç»ƒä»¥æé«˜é€Ÿåº¦

## å‚è€ƒæ–‡çŒ®

- Vaswani, A., et al. (2017). "Attention is All You Need."